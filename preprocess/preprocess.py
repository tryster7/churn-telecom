from __future__ import absolute_import, division, print_function, unicode_literals

import pathlib
import argparse
import sys
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow import feature_column
from tensorflow.python.lib.io import file_io

import os

from google.cloud import storage

def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument('--bucket_name',
                        type=str,
                        default='gs://',
                        help='The bucket where the output has to be stored')

    parser.add_argument('--input_file_with_folder',
                        type=str,
                        default='input\churn.csv',
                        help='The folder where input files are to be read from')

    parser.add_argument('--output_folder',
                        type=str,
                        default='output',
                        help='The folder where output files are to be stored')

    args = parser.parse_known_args()[0]
    return args

def churn_to_numeric(value):
    if value.lower() == 'yes':
        return 1
    return 0

def normalize(df, cols):
    result = df.copy()
    for feature_name in cols:
        max_value = df[feature_name].max()
        min_value = df[feature_name].min()
        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
    return result

def extractNumericCols(df):
    cols = []
    for col in df.columns:
        if df[col].dtype.name != 'object':
            cols.append(col)
    return cols

def write_output_files(df, bucket_name, folder, file_name):
    file = bucket_name + os.path.sep + folder + os.path.sep + file_name
    with file_io.FileIO(file, 'w') as f:
        df.to_csv(f, index=False)


def preprocess(input_file, output_folder, bucket_name):

    input_file = bucket_name + os.path.sep + input_file
    print('Input file is {}'.format(input_file))

    df = pd.read_csv(input_file)

    df = df.drop(columns=['customerID'])
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    #Convert the Senior Citizen Column to Categorical Column
    df['SeniorCitizen'] = df['SeniorCitizen'].apply(lambda x: 'Yes' if x == 1 else 'No')
    #Replace empty strings with charges generated by multiplying tenure with monthly charge
    df['TotalCharges'].fillna(value=df['tenure'] * df['MonthlyCharges'], inplace=True)
    #Convert the prediction label to numeric value
    df['Churn'] = df['Churn'].apply(churn_to_numeric)

    #Normalize the numeric fields
    cols = extractNumericCols(df)
    dfn = normalize(df, cols)

    #split the dataset/dataframe into train, validation and test datasets
    train_ds = dfn.sample(frac=0.6, random_state=0)
    validation_ds = df.drop(train_ds.index)
    test_ds = validation_ds.sample(frac=0.30, random_state=0)

    train_labels = train_ds.pop('Churn').to_frame()
    validation_labels = validation_ds.pop('Churn').to_frame()
    test_labels = test_ds.pop('Churn').to_frame()

    write_output_files(train_ds, bucket_name, output_folder, 'train.csv')
    write_output_files(train_labels, bucket_name, output_folder, 'train_labels.csv')
    write_output_files(validation_ds, bucket_name, output_folder, 'validation.csv')
    write_output_files(validation_labels, bucket_name, output_folder, 'validation_labels.csv')
    write_output_files(test_ds, bucket_name, output_folder, 'test.csv')
    write_output_files(test_labels, bucket_name, output_folder, 'test_labels.csv')


if __name__ == '__main__':
    
    args = parse_arguments()
    print(args)
    preprocess(args.input_file_with_folder, args.output_folder, args.bucket_name)

